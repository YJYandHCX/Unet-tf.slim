{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import DATA\n",
    "import Net\n",
    "import config as cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "slim = tf.contrib.slim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/yanjianyu/mine/tensorflow/segementation/cat and dog/Net.py:69: calling argmax (from tensorflow.python.ops.math_ops) with dimension is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the `axis` argument instead\n"
     ]
    }
   ],
   "source": [
    "data = DATA.CADF()\n",
    "net = Net.Unet(True)\n",
    "global_step = tf.train.create_global_step()\n",
    "learning_rate = 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./save/model.ckpt-1102\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "tf.summary.scalar('learning_rate',learning_rate)\n",
    "train_step = tf.train.GradientDescentOptimizer(learning_rate).minimize(net.total_loss, global_step=global_step)\n",
    "sess = tf.Session()\n",
    "variable_to_restore = tf.global_variables()\n",
    "saver = tf.train.Saver(variable_to_restore)\n",
    "ckpt = tf.train.get_checkpoint_state('./save/')\n",
    "if ckpt and ckpt.model_checkpoint_path:\n",
    "    saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "    print(\"OK\")\n",
    "summary_op = tf.summary.merge_all()\n",
    "writer = tf.summary.FileWriter(\"./Summ/\",sess.graph,flush_secs=60)\n",
    "\n",
    "with tf.control_dependencies([train_step]):\n",
    "    train_op = tf.no_op(name='train')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After 1102 training step(s), loss on training batch is 0.530617.\n",
      "After 1102 training step(s), loss on training batch is 0.530617.\n",
      "After 1112 training step(s), loss on training batch is 0.514033.\n",
      "After 1122 training step(s), loss on training batch is 0.431974.\n",
      "After 1132 training step(s), loss on training batch is 0.408972.\n",
      "After 1142 training step(s), loss on training batch is 0.542811.\n",
      "After 1152 training step(s), loss on training batch is 0.511444.\n",
      "After 1162 training step(s), loss on training batch is 0.487134.\n",
      "After 1172 training step(s), loss on training batch is 0.570983.\n",
      "After 1182 training step(s), loss on training batch is 0.516454.\n",
      "After 1192 training step(s), loss on training batch is 0.477846.\n",
      "After 1202 training step(s), loss on training batch is 0.536775.\n",
      "After 1202 training step(s), loss on training batch is 0.536775.\n",
      "After 1212 training step(s), loss on training batch is 0.517235.\n",
      "After 1222 training step(s), loss on training batch is 0.429489.\n",
      "After 1232 training step(s), loss on training batch is 0.403491.\n",
      "After 1242 training step(s), loss on training batch is 0.541667.\n",
      "After 1252 training step(s), loss on training batch is 0.512865.\n",
      "After 1262 training step(s), loss on training batch is 0.482796.\n",
      "After 1272 training step(s), loss on training batch is 0.559639.\n",
      "After 1282 training step(s), loss on training batch is 0.520063.\n",
      "After 1292 training step(s), loss on training batch is 0.477809.\n",
      "After 1302 training step(s), loss on training batch is 0.542154.\n",
      "After 1302 training step(s), loss on training batch is 0.542154.\n"
     ]
    }
   ],
   "source": [
    "for i in range (205):\n",
    "    xs,ys = data.batch_prepare(i)\n",
    "    feed_dict = {net.images:xs,net.labels:ys} \n",
    "    if i%10==0:\n",
    "        summary_str,loss_value,_,step = sess.run([summary_op,net.total_loss,\n",
    "                                                        train_op,global_step],feed_dict = feed_dict)\n",
    "        writer.add_summary(summary_str,step)\n",
    "        print(\"After %d training step(s), loss on training \"\n",
    "                      \"batch is %g.\" % (step, loss_value))\n",
    "    else :\n",
    "        summary_str,loss_value,_,step = sess.run([summary_op,net.total_loss,train_op,global_step],\n",
    "                                                 feed_dict = feed_dict)\n",
    "    if i % 100 == 0:\n",
    "        print(\"After %d training step(s), loss on training \"\n",
    "                      \"batch is %g.\" % (step, loss_value))\n",
    "        saver.save(sess,\"./save/model.ckpt\",global_step)\n",
    "print(\"training is ending\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
